Lexical Overlap:
    Train:    0.541
    Dev:      0.535
    Test:     0.499
--------------------------------------
Cosine Similarity:
    Train:    0.795 (miniLM)
    Dev:      0.796 (miniLM)
    Test:     0.782 (miniLM)
Best Transformer: miniLM
--------------------------------------
Siamese MLP:
    Train:    0.997
    Dev:      0.690
    Test:     0.673
Best hyperparameters:
    Transformer: miniLM
    Architecture size: Medium+Small
    Activation function: ReLU
    Dropout: 0.001
    Optimizer: RMSprop
    Learning rate: 4.84e-5
    Weight decay: 3.6e-6
    Early stopping: None
    Patience: -
    Batch size: 16
    Epochs: 191
--------------------------------------
Siamese LSTM:
    Train:    0.
    Dev:      0.
    Test:     0.
Best hyperparameters:
    Transformer:
    Hidden dim factor:
    Number of layers:
    Optimizer:
    Learning rate:
    Weight decay:
    Early stopping:
    Patience:
    Batch size:
    Epochs:
--------------------------------------